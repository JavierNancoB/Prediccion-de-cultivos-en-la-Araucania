{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee53651-c4db-43df-b1b3-e1d6de4fcc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Usando dataset: features_trigo.csv\n",
      "\n",
      "Modelos disponibles:\n",
      "1. CatBoost.joblib\n",
      "2. KNN.joblib\n",
      "3. Lasso.joblib\n",
      "4. LightGBM.joblib\n",
      "5. MLP_final_model.h5\n",
      "6. MLP_Mejorado.joblib\n",
      "7. MLP_mejor_modelo.h5\n",
      "8. RandomForest_Mejorado.joblib\n",
      "9. Random_Forest.joblib\n",
      "10. RedNeuronal_Mejorada.joblib\n",
      "11. Regresión_Lineal.joblib\n",
      "12. Ridge.joblib\n",
      "13. SVR.joblib\n",
      "14. XGBoost.joblib\n",
      "15. XGBoost_Mejorado.joblib\n",
      "16. Árbol.joblib\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ingresa el número del modelo a utilizar:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Cargando modelo: KNN.joblib\n",
      "\n",
      "📊 Resultados del modelo:\n",
      "Modelo: KNN.joblib\n",
      "R²: -2.566\n",
      "MAE: 1231.64\n",
      "RMSE: 1393.83\n",
      "MAPE: 23.58%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ===========================\n",
    "# Dataset\n",
    "# ===========================\n",
    "dataset = \"features_trigo.csv\"\n",
    "if not os.path.isfile(dataset):\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo {dataset} en la carpeta actual.\")\n",
    "\n",
    "data = pd.read_csv(dataset)\n",
    "print(f\"🔹 Usando dataset: {dataset}\")\n",
    "\n",
    "# ===========================\n",
    "# Variables y Features derivadas\n",
    "# ===========================\n",
    "data['GDD_norm'] = data['Temp_media'].apply(lambda x: max(x - 10, 0)) / data['Horas_luz']\n",
    "data['Indice_fertilidad'] = 0.5*data['N_kg_ha'] + 0.3*data['P_kg_ha'] + 0.2*data['K_kg_ha']\n",
    "\n",
    "def clasificar_clima(row):\n",
    "    if row['Lluvia_mm'] > 600 and row['Temp_media'] < 18:\n",
    "        return 'húmedo_frío'\n",
    "    elif row['Lluvia_mm'] < 300 and row['Temp_media'] > 20:\n",
    "        return 'seco_calido'\n",
    "    else:\n",
    "        return 'moderado'\n",
    "\n",
    "data['Clima_reglas'] = data.apply(clasificar_clima, axis=1)\n",
    "data['Rango_termico'] = data['Temp_max'] - data['Temp_min']\n",
    "\n",
    "def categorizar_rango(rango):\n",
    "    if rango < 6:\n",
    "        return 'estable'\n",
    "    elif rango <= 10:\n",
    "        return 'moderado'\n",
    "    else:\n",
    "        return 'variable'\n",
    "\n",
    "data['Rango_termico_cat'] = data['Rango_termico'].apply(categorizar_rango)\n",
    "data['Labranza_binary'] = data['Labranza'].apply(lambda x: 1 if x=='convencional' else 0)\n",
    "data['Plagas_binary'] = data['Plagas'].apply(lambda x: 1 if x=='sí' else 0)\n",
    "data['Deficiencia_binary'] = data['Deficiencia'].apply(lambda x: 1 if x=='sí' else 0)\n",
    "data['Problema'] = data['Plagas_binary'] + data['Deficiencia_binary']\n",
    "\n",
    "# Convertir columnas categóricas a dummies\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'Rendimiento_kg_ha' in categorical_cols:\n",
    "    categorical_cols.remove('Rendimiento_kg_ha')\n",
    "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Separar X y y\n",
    "X = data.drop(columns=[\"Rendimiento_kg_ha\"])\n",
    "y = data[\"Rendimiento_kg_ha\"]\n",
    "\n",
    "# ===========================\n",
    "# Listar modelos disponibles\n",
    "# ===========================\n",
    "models_path = \"./modelos/\"\n",
    "if not os.path.isdir(models_path):\n",
    "    raise FileNotFoundError(f\"No se encontró la carpeta de modelos: {models_path}\")\n",
    "\n",
    "model_files = [f for f in os.listdir(models_path)\n",
    "               if f.endswith(\".h5\") or (f.endswith(\".joblib\") and \"scaler\" not in f.lower())]\n",
    "\n",
    "print(\"\\nModelos disponibles:\")\n",
    "for i, m in enumerate(model_files, 1):\n",
    "    print(f\"{i}. {m}\")\n",
    "\n",
    "# ===========================\n",
    "# Selección de modelo\n",
    "# ===========================\n",
    "choice = int(input(\"\\nIngresa el número del modelo a utilizar: \")) - 1\n",
    "modelo_elegido = model_files[choice]\n",
    "print(f\"\\n🔹 Cargando modelo: {modelo_elegido}\")\n",
    "\n",
    "# ===========================\n",
    "# Detectar scaler asociado\n",
    "# ===========================\n",
    "scaler = None\n",
    "scaler_name = \"scaler_\" + modelo_elegido.replace(\".joblib\", \"\").replace(\".h5\", \"\") + \".joblib\"\n",
    "if scaler_name in os.listdir(models_path):\n",
    "    print(f\"⚡ Se detectó scaler asociado: {scaler_name}\")\n",
    "    scaler = joblib.load(os.path.join(models_path, scaler_name))\n",
    "    X_scaled = scaler.transform(X)\n",
    "else:\n",
    "    X_scaled = X.values\n",
    "\n",
    "X_scaled = X_scaled.astype(np.float32)\n",
    "\n",
    "# ===========================\n",
    "# Cargar modelo\n",
    "# ===========================\n",
    "if modelo_elegido.endswith(\".joblib\"):\n",
    "    model = joblib.load(os.path.join(models_path, modelo_elegido))\n",
    "    es_keras = False\n",
    "elif modelo_elegido.endswith(\".h5\"):\n",
    "    model = load_model(os.path.join(models_path, modelo_elegido))\n",
    "    es_keras = True\n",
    "else:\n",
    "    raise ValueError(\"Formato de modelo no soportado\")\n",
    "\n",
    "# ===========================\n",
    "# Predicciones\n",
    "# ===========================\n",
    "if hasattr(model, \"predict\"):\n",
    "    if es_keras:\n",
    "        y_pred = model.predict(X_scaled, verbose=0)\n",
    "        if y_pred.ndim > 1 and y_pred.shape[1] == 1:\n",
    "            y_pred = y_pred.flatten()\n",
    "    else:\n",
    "        y_pred = model.predict(X_scaled)\n",
    "else:\n",
    "    y_pred = model(X_scaled).flatten()\n",
    "\n",
    "# ===========================\n",
    "# Métricas\n",
    "# ===========================\n",
    "r2 = r2_score(y, y_pred)\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "print(\"\\n📊 Resultados del modelo:\")\n",
    "print(f\"Modelo: {modelo_elegido}\")\n",
    "print(f\"R²: {r2:.3f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b1616-ee85-46f8-be3e-f00a60436f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
