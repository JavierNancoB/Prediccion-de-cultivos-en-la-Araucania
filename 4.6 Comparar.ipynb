{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78d3ae4-c029-4d5e-9b34-7e353cf99411",
   "metadata": {},
   "source": [
    "##  Evaluación comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055baaf-8220-4b2f-9677-0ef43e30d7e5",
   "metadata": {},
   "source": [
    "Grupo: 1\n",
    "\n",
    "Estudiantes:\n",
    "\n",
    "-Constanza Olivos Fernandez\n",
    "\n",
    "-Javier Nanco Becerra\n",
    "\n",
    "-Nicolás Pozo Villagrán\n",
    "\n",
    "Fecha: 20-09-2025\n",
    "\n",
    "Version: 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02dd26-e57a-43bc-9cc1-67529d6ef1d0",
   "metadata": {},
   "source": [
    "# Objetivos del notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf1550-79c7-4241-909b-e1e9952e8347",
   "metadata": {},
   "source": [
    "En esta sección se realiza una comparación integral del desempeño de todos los modelos entrenados (clásicos, modernos y el MLP optimizado) utilizando el conjunto de prueba. Para ello, se calculan y consolidan las métricas MAE, RMSE, R² y MAPE, las cuales permiten evaluar tanto la precisión como la estabilidad de cada modelo.\n",
    "\n",
    "El proceso incluye:\n",
    "\n",
    "La lectura de los archivos de resultados individuales generados en etapas anteriores.\n",
    "\n",
    "La unificación de todas las métricas en un único DataFrame.\n",
    "\n",
    "La clasificación de los modelos en dos grupos: Anteriores (modelos clásicos y boosting) y Optimizados (modelos modernos y MLP optimizado).\n",
    "\n",
    "La ordenación de los resultados por R² descendente, lo que permite identificar los modelos con mejor capacidad predictiva.\n",
    "\n",
    "La exportación de la tabla final a un archivo CSV para su posterior análisis y visualización en informes o herramientas externas.\n",
    "\n",
    "De este modo, se obtiene una tabla comparativa completa que facilita la identificación de los modelos más robustos y consistentes, brindando evidencia objetiva para la selección del mejor enfoque en la predicción del rendimiento del trigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d30ec4a1-6b3d-4b8e-a612-abe355695c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelos Optimizado / Mejorado:\n",
      "              Modelo        R²     R²_CV        RMSE         MAE  MAPE (%)  \\\n",
      "10          CatBoost  0.830510       NaN  304.688421  239.515335  4.881455   \n",
      "9           LightGBM  0.826762       NaN  308.039440  242.200684  4.937405   \n",
      "8            XGBoost  0.825747       NaN  308.939874  243.050112  4.957638   \n",
      "0                MLP  0.794230  0.732465  335.718683  263.637716  5.384025   \n",
      "5      Random Forest  0.819684       NaN  314.268494  247.256763  5.041656   \n",
      "7                KNN  0.760639       NaN  362.085107  286.914409  5.911103   \n",
      "1   Regresión Lineal  0.701081       NaN  404.632495  315.828222  6.565522   \n",
      "3              Lasso  0.701075       NaN  404.636908  315.850907  6.565973   \n",
      "2              Ridge  0.701032       NaN  404.666045  315.979182  6.568551   \n",
      "6                SVR  0.643299       NaN  442.014200  352.208376  7.435710   \n",
      "4              Árbol  0.639440       NaN  444.398956  351.665011  7.173763   \n",
      "\n",
      "        Estado  \n",
      "10  Optimizado  \n",
      "9   Optimizado  \n",
      "8   Optimizado  \n",
      "0   Optimizado  \n",
      "5     Anterior  \n",
      "7     Anterior  \n",
      "1     Anterior  \n",
      "3     Anterior  \n",
      "2     Anterior  \n",
      "6     Anterior  \n",
      "4     Anterior  \n",
      "✅ Tabla comparativa guardada en 'csv/comparacion_modelos_trigo_distinguido.csv'\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Comparación final distinguida\n",
    "# ===========================\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# ===========================\n",
    "# 1. Leer todos los CSV de resultados\n",
    "# ===========================\n",
    "archivos_resultados = glob.glob(\"csv/resultados_*.csv\")  # Ajusta según tus archivos\n",
    "\n",
    "lista_df = []\n",
    "for archivo in archivos_resultados:\n",
    "    df = pd.read_csv(archivo)\n",
    "    \n",
    "    # Agregar columna para distinguir optimizados\n",
    "    if \"mlp\" in archivo.lower() or \"modernos\" in archivo.lower():\n",
    "        df[\"Estado\"] = \"Optimizado\"\n",
    "    else:\n",
    "        df[\"Estado\"] = \"Anterior\"\n",
    "    \n",
    "    lista_df.append(df)\n",
    "\n",
    "# ===========================\n",
    "# 2. Combinar todos los resultados\n",
    "# ===========================\n",
    "df_comparativo = pd.concat(lista_df, ignore_index=True)\n",
    "\n",
    "# ===========================\n",
    "# 3. Ordenar por R² descendente dentro de cada grupo\n",
    "# ===========================\n",
    "df_comparativo = df_comparativo.sort_values(by=[\"Estado\", \"R²\"], ascending=[False, False])\n",
    "\n",
    "# ===========================\n",
    "# 4. Separar por grupos para ver más claro\n",
    "# ===========================\n",
    "df_optimizado = df_comparativo[df_comparativo[\"Estado\"] == \"Optimizado\"]\n",
    "df_anterior = df_comparativo[df_comparativo[\"Estado\"] == \"Anterior\"]\n",
    "\n",
    "print(\"✅ Modelos Optimizado / Mejorado:\")\n",
    "print(df_comparativo)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# ===========================\n",
    "# 5. Guardar CSV final distinguido en la carpeta 'csv'\n",
    "# ===========================\n",
    "output_path = os.path.join('csv', 'comparacion_modelos_trigo_distinguido.csv')\n",
    "df_comparativo.to_csv(output_path, index=False)\n",
    "print(\"✅ Tabla comparativa guardada en 'csv/comparacion_modelos_trigo_distinguido.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e0ce2-f47d-4a1c-afca-6d959c6ff955",
   "metadata": {},
   "source": [
    "La evaluación comparativa evidencia que los modelos modernos optimizados (CatBoost, LightGBM y XGBoost) superan consistentemente a los modelos clásicos en términos de precisión y error. CatBoost se posiciona como el mejor modelo, alcanzando un R² = 0.83 y el menor error absoluto (MAE ≈ 239.5), lo que refleja alta capacidad predictiva y generalización confiable.\n",
    "\n",
    "El MLP optimizado también mostró un buen desempeño (R² = 0.79, MAPE ≈ 5.38%), quedando por debajo de los modelos de boosting, pero por encima de varios algoritmos clásicos. En contraste, los métodos lineales (Regresión Lineal, Ridge y Lasso) y los modelos de menor complejidad (Árbol de decisión, SVR) presentaron limitaciones claras, con R² ≤ 0.70 y mayores niveles de error.\n",
    "\n",
    "En conjunto, los resultados sugieren que los enfoques de boosting (CatBoost, LightGBM y XGBoost) son los más adecuados para predecir el rendimiento del trigo, entregando estimaciones más estables y precisas, mientras que los modelos clásicos solo resultan útiles como referencia base o para escenarios con menor complejidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
